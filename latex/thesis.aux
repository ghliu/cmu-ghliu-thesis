\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{deepdriving,nvidiacar,endtoendcars}
\citation{ross2011reduction}
\citation{mnih2013playing,mnih2015human,2016-TOG-deepRL}
\citation{multimodaltartan}
\citation{elfring2016multisensor,cho2014multi,darms2008classification}
\citation{qureshi2016robot}
\citation{levine2016end}
\citation{mirowski2017a}
\citation{wymann2000torcs}
\citation{CDQN}
\citation{DBLP:journals/corr/LillicrapHPHETS15}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{dropout}
\citation{blockout}
\citation{dropconnect}
\citation{zoneout}
\citation{moddrop}
\citation{modout}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Kinodynamic Planning for All-Terrain Vehicle}{3}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:rrtplanner}{{2}{3}{Kinodynamic Planning for All-Terrain Vehicle}{chapter.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Deep Inverse Reinforcement Learning}{5}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:dirl}{{3}{5}{Deep Inverse Reinforcement Learning}{chapter.3}{}}
\citation{deepdriving,nvidiacar,endtoendcars}
\citation{ross2011reduction}
\citation{mnih2013playing,mnih2015human,2016-TOG-deepRL}
\citation{multimodaltartan}
\citation{elfring2016multisensor,cho2014multi,darms2008classification}
\citation{qureshi2016robot}
\citation{levine2016end}
\citation{mirowski2017a}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Multimodal Deep Reinforcement Learning}{7}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chap:multimodalDRL}{{4}{7}{Multimodal Deep Reinforcement Learning}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{7}{section.4.1}}
\citation{wymann2000torcs}
\citation{CDQN}
\citation{DBLP:journals/corr/LillicrapHPHETS15}
\citation{dropout}
\citation{blockout}
\citation{dropconnect}
\citation{zoneout}
\citation{moddrop}
\citation{modout}
\citation{mnih2013playing}
\citation{DBLP:journals/corr/LillicrapHPHETS15,A3C,CDQN,TRPO}
\citation{sutton1999policy}
\citation{CDQN}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Background}{9}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Deep Reinforcement Learning (DRL)}{9}{subsection.4.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Normalized Advantage Function (NAF)}{9}{subsection.4.2.2}}
\newlabel{sec:CDQN}{{4.2.2}{9}{Normalized Advantage Function (NAF)}{subsection.4.2.2}{}}
\citation{dpg}
\citation{dpg}
\citation{DBLP:journals/corr/LillicrapHPHETS15}
\citation{mnih2015human}
\citation{mnih2015human}
\citation{uhlenbeck1930theory}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Schematic illustration of (a) forward and (b) back-propagation for NAF, and (c) forward and (d) back-propagation for DDPG. Green modules are functions approximated with Deep Nets.\relax }}{10}{figure.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:CDQN-DDPG}{{4.1}{10}{Schematic illustration of (a) forward and (b) back-propagation for NAF, and (c) forward and (d) back-propagation for DDPG. Green modules are functions approximated with Deep Nets.\relax }{figure.caption.4}{}}
\newlabel{equ:NAF}{{4.4}{10}{Normalized Advantage Function (NAF)}{equation.4.2.4}{}}
\newlabel{equ:P}{{4.5}{10}{Normalized Advantage Function (NAF)}{equation.4.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Deep Deterministic Policy Gradient (DDPG)}{10}{subsection.4.2.3}}
\newlabel{dpg}{{4.6}{10}{Deep Deterministic Policy Gradient (DDPG)}{equation.4.2.6}{}}
\citation{hudda2013self}
\citation{dropout}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Multimodal Deep Reinforcement Learning}{11}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Multimodal Network Architecture}{11}{subsection.4.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Sensor Dropout (SD)}{11}{subsection.4.3.2}}
\newlabel{sec:SD}{{4.3.2}{11}{Sensor Dropout (SD)}{subsection.4.3.2}{}}
\citation{dropout}
\citation{dropout}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Illustration of Multimodal Architecture and Sensor Dropout. The feature extraction module can be either pure identity function (modality $1$), or convolution-based layer (modality $2 \to M$). The operation $*$ stands for element-wised multiplication.\relax }}{12}{figure.caption.5}}
\newlabel{fig:Multi-SD}{{4.2}{12}{Illustration of Multimodal Architecture and Sensor Dropout. The feature extraction module can be either pure identity function (modality $1$), or convolution-based layer (modality $2 \to M$). The operation $*$ stands for element-wised multiplication.\relax }{figure.caption.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces M-DRL with Sensor Dropout\relax }}{13}{algorithm.1}}
\newlabel{alg:mdrl-algo}{{1}{13}{M-DRL with Sensor Dropout\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Augmenting Experience Replay}{13}{section*.6}}
\citation{wymann2000torcs}
\citation{wymann2000torcs}
\citation{GymTORCS}
\citation{uhlenbeck1930theory}
\citation{DBLP:journals/corr/LillicrapHPHETS15}
\citation{A3C}
\citation{BenLau16}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Platform Setup}{14}{subsection.4.3.3}}
\newlabel{sec:platform}{{4.3.3}{14}{Platform Setup}{subsection.4.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{TORCS Simulator:}{14}{section*.7}}
\newlabel{fig:training_exp_naf}{{4.3a}{15}{NAF\relax }{figure.caption.8}{}}
\newlabel{sub@fig:training_exp_naf}{{a}{15}{NAF\relax }{figure.caption.8}{}}
\newlabel{fig:training_exp_ddpg}{{4.3b}{15}{DDPG\relax }{figure.caption.8}{}}
\newlabel{sub@fig:training_exp_ddpg}{{b}{15}{DDPG\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Training performance comparison of three baseline single sensor policies, and the proposed multi-modal policies, with and without Sensor Dropout.\relax }}{15}{figure.caption.8}}
\newlabel{fig:training_exp}{{4.3}{15}{Training performance comparison of three baseline single sensor policies, and the proposed multi-modal policies, with and without Sensor Dropout.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Results}{15}{subsection.4.3.4}}
\newlabel{sec:policy}{{4.3.4}{15}{Results}{figure.caption.10}{}}
\newlabel{fig:actual_robust_naf}{{4.4a}{16}{NAF\relax }{figure.caption.9}{}}
\newlabel{sub@fig:actual_robust_naf}{{a}{16}{NAF\relax }{figure.caption.9}{}}
\newlabel{fig:actual_robust_ddpg}{{4.4b}{16}{DDPG\relax }{figure.caption.9}{}}
\newlabel{sub@fig:actual_robust_ddpg}{{b}{16}{DDPG\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Policy Robustness Analysis: Darker lines connects average rewards of leaned policies with accurate sensing while the lighter lines connects the corresponding policies in the face of sensor noise.\relax }}{16}{figure.caption.9}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Results of the $\mathcal  {T}_2^1$ dependency metric.\relax }}{16}{table.caption.11}}
\newlabel{table:policy-ratio}{{4.1}{16}{Results of the $\mathcal {T}_2^1$ dependency metric.\relax }{table.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Probing through the gradients}{16}{subsection.4.3.5}}
\@writefile{toc}{\contentsline {subsubsection}{Dependency metric:}{16}{section*.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Policy Sensitivity to Sensor Failure: The blue, green, and red bars denote full multi-modal policy, multi-modal with no image input, and multi-modal with no laser and physical state input, respectively.\relax }}{17}{figure.caption.10}}
\newlabel{fig:policy_exp}{{4.5}{17}{Policy Sensitivity to Sensor Failure: The blue, green, and red bars denote full multi-modal policy, multi-modal with no image input, and multi-modal with no laser and physical state input, respectively.\relax }{figure.caption.10}{}}
\newlabel{equ:grad_metric}{{4.10}{17}{Dependency metric:}{equation.4.3.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{Visualizing weights:}{17}{section*.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The visualization of the magnitude of gradient for each neuron on training environment. The whiter color means the higher gradient. The color bar represents three different sensor modules: physical state(blue), Laser(green), and Image(red).\relax }}{18}{figure.caption.13}}
\newlabel{fig:grad_exp}{{4.6}{18}{The visualization of the magnitude of gradient for each neuron on training environment. The whiter color means the higher gradient. The color bar represents three different sensor modules: physical state(blue), Laser(green), and Image(red).\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Discussion}{18}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Sensor Dropout v/s \emph  {traditional} Dropout}{18}{subsection.4.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces The gradient responses of actions on the image input for each of the multi-modal agents. The top $20\%$ gradients are marked red.\relax }}{19}{figure.caption.15}}
\newlabel{fig:grad_exp_img}{{4.7}{19}{The gradient responses of actions on the image input for each of the multi-modal agents. The top $20\%$ gradients are marked red.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Fusion Layer Configurations}{19}{subsection.4.4.2}}
\newlabel{sec:SD-config}{{4.4.2}{19}{Fusion Layer Configurations}{subsection.4.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Implementation of NAF with Multi-modal}{19}{subsection.4.4.3}}
\newlabel{discussion-NAF}{{4.4.3}{19}{Implementation of NAF with Multi-modal}{subsection.4.4.3}{}}
\citation{amos2016input}
\citation{TRPO}
\citation{levine2013guided}
\citation{DBLP:journals/corr/GuLGTL16}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Conclusions and Future Work}{20}{section.4.5}}
\bibstyle{plainnat}
\bibdata{MDRLBib}
\citation{*}
